'''
Natural Language Processing Final Project
Markov Model based chatbot - BotBuddy

Hannah Kerr
'''

import nltk
import re
import random
import markov
import string    # for string.punctuation
import warnings
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

GREETING_INPUTS = ['hello', 'hi', 'greetings', 'sup', 'hey']
GREETING_RESPONSES = ['Hi.', 'Hey!', '*Nods*', 'Hi there!', 'Hello.']
GOODBYE_INPUTS = ['see ya', 'goodbye', 'bye', 'gotta go']
GOODBYE_RESPONSES = ['bye!', 'see ya', 'later dude', 'goodbye']

NAME = "BotBuddy"
dictFile = 'MarkovDict.txt'
def genDict():
	'''
	Generate the Markov Chain transition matrix. **This function should be run once to generate the dictionary file,
	after the file is created it does not need to be run unless changes are made
	'''
	markovObj = markov.Markov()	#Create new Markov object
	# print(fileList)
	fileList =['formatted_movie_lines.txt']  #file of dialog from the Cornell Movie Dialog Corpus
	for file in fileList:
		try:
			markovObj.readFile(file, "utf-8")
		except:
			markovObj.readFile(file, "windows-1252")

	markovObj.outputDict("MarkovDict.txt") #generate the dictionary
	print( "Generated Markov dictionary %s with processing %s input lines and %s input words " % ( "dict.txt", str(markovObj.getLineCount()), str(markovObj.getWordCount()) ) )

def genText(seed, genNSent, markovObj):
	'''
	This function generates sentences based on the Markov model and the given seed words
	Parameters:
		seed: the selected seed word of the sentences
		genNSent: the number of sentences to be generated
		markovObj: the Markov model object
	Return:
		generated: a list of sentences generated by the Markov object
	'''
	generated = []
	for sentence in range(genNSent):
		text = markovObj.genText(seed)
		#print(text)
		generated.append(text)
	return generated

def removePunct(text):
    '''Make text lower-case and remove punctuation.'''

    table = str.maketrans('', '', string.punctuation)
    return text.lower().translate(table)

def greeting(sentence):
    '''
	Return True if sentence contains a greeting word; False otherwise.
	'''
    sentence = removePunct(sentence)
    for word in sentence.split():
        if word.lower() in GREETING_INPUTS:
            return True
    return False

def normalize(text):
    '''Return normalized and lemmatized tokens in text.'''
    text = removePunct(text)
    tokens = nltk.word_tokenize(text)
    lemmatizer = nltk.stem.WordNetLemmatizer()
    return [lemmatizer.lemmatize(token) for token in tokens]

def similarity(generatedResponses, userInput):
	'''Returns the sentence that is most similar to user input using TF-IDF.
	Parameters:
		generatedResponses: a list of candidate responses
		userInput: the string of input given by the user
	Returns:
		The response most similar to the users input, or a random response if there is no similar option
	'''
	warnings.filterwarnings("ignore", category=FutureWarning)

	sentences = generatedResponses + [userInput]
	tfidfVec = TfidfVectorizer(tokenizer = normalize, stop_words = 'english')
	tdMatrix = tfidfVec.fit_transform(sentences)      # get our term-document matrix
	cosines = cosine_similarity(tdMatrix[-1], tdMatrix)  # cos similarity between input and all sents
	cosines = cosines.flatten()[:-1]                     # flatten to 1-D and remove cos(input, input)
	if(cosines.max() == 0):
		return random.choice(generatedResponses[:-1]) #if nothing is similar, return a random response
	else:
		return sentences[cosines.argmax()]  # or remove +1 to return match

def parseInput(userInput):
	'''Uses nltk's pos_tag to tag the parts of speech of the users input'''
	tokens = nltk.word_tokenize(userInput)
	pos = nltk.pos_tag(tokens)
	return pos

def getPOS(parsedInput):
	'''Select the pronoun, verb, and noun from the users input. If not present each defaults to None'''
	pronoun = None
	verb = None
	noun = None
	for word, pos in parsedInput:
		if pos in ["VB", "VBD", "VBG", "VBN", "VBP", "VBZ"]:
			verb = word
		elif pos == "NN" or pos == "NNS":
			noun = word
		elif pos == "PRP" or pos == "PRP$":
					pronoun = word
	return pronoun, verb, noun

def genResponse(pronoun, verb, noun, markovObj, userInput):
	'''
	This function selects the seed word and generates 200 responses from the Markov object
	Parameters:
		pronoun: the token of userInput tagged as a pronoun, or None if no pronoun was present
		verb: the token of userInput tagged as a verb, or None if no verb was present
		noun: the token of userInput tagged as a noun, or None if no noun was present
		markovObj: the Markov Model object
		userInput: a string of the users input
	Returns:
		mostSim: the generated response most similar to the usersInput
	'''
	if noun: 	#If a noun is present in the userInput, first use the noun as the seed word
		generated = genText(noun, 200, markovObj)
	elif verb:  #If there was no noun, use the verb as the seed
		generated = genText(verb, 200, markovObj)
	elif pronoun: 	#If there was no verb, use the pronoun as the seed
		generated = genText(pronoun, 200, markovObj)
	else: 		#If the userInput did not contain any of the above, allow the genText function to select a random seed word
		generated = genText(None, 200, markovObj)
	mostSim = similarity(generated, userInput)  #calculate the most similar response from the 200
	return mostSim


def knockknock(userName):
	'''
	This function adds BotBuddy's knock knock joke telling funcitonality.
	Reading in a text file of jokes, this function uses reg ex to determine if the user entered the correctly formatted responses
	'''
	jokes = []
	file = open('knockknock.txt', 'r', encoding="utf-8").read().split('\n')
	for line in file:
		joke = line.split(',')
		if len(joke) == 3:
			jokes.append(joke)
	print(NAME + ": Knock knock\n")
	userInput = input(userName + ': ').lower()
	print()
	if re.match(r"who[' ]?i?s there\??", userInput):
		pick = random.choice(jokes)
		print(NAME + ': ' + pick[0] + '\n')
		userInput2 = input(userName + ': ').lower()
		print()
		resp = pick[1].lower()
		if userInput2 == resp[1:] or userInput2 == resp[1:-1]:
			print(NAME + ': ' + pick[2])
		else:
			print(NAME + ': Do you understand knock knock jokes? Try again\n')
			knockknock(userName)
	else:
		print(NAME + ': Do you understand knock knock jokes? Try again\n')
		knockknock(userName)

def main():
	'''
	This is the main function to call BotBuddy
	'''
	genDict() #**ONLY RUN ONCE,	comment out after inital run and the file is generated. Running this line will take about 3-5 min
	markovObj = markov.Markov(dictFile = dictFile, maxWordInSentence=20)
	print(NAME, ": My name is BotBuddy, what is your name?")
	userName = input("Enter your name: ")
	print(NAME,": Hi ", userName, "! Let's chat :)")
	while True:
		userInput = input('\n'+ userName +": ").lower()
		print()
		parsedInput = parseInput(userInput)
		pronoun, verb, noun = getPOS(parsedInput)
		if userInput in GOODBYE_INPUTS: 	#check for goodbye
			print(NAME +': ' + random.choice(GOODBYE_RESPONSES))
			break
		elif greeting(userInput): #check for a greeting
			print(NAME + ': ' + random.choice(GREETING_RESPONSES))
		elif re.match(r".*knock[- ]?knock joke", userInput): 	#check for knock knock joke
			knockknock(userName)
		else: 	#generate a response
			print(NAME + ': ' + genResponse(pronoun, verb, noun, markovObj, userInput) )
main()
